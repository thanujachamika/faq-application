{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "E0acWkfLAIv5",
    "outputId": "f3ffaca6-b25b-4edc-fef4-89bb041484be",
    "ExecuteTime": {
     "end_time": "2024-05-13T01:29:53.765550Z",
     "start_time": "2024-05-13T01:29:50.125518Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T01:30:00.004659Z",
     "start_time": "2024-05-13T01:29:58.738584Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "question = df['Question']\n",
    "answer = df['Answer']"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bauZhEsrA_Bp",
    "ExecuteTime": {
     "end_time": "2024-05-13T01:30:07.195070Z",
     "start_time": "2024-05-13T01:30:01.951338Z"
    }
   },
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T01:30:11.668906Z",
     "start_time": "2024-05-13T01:30:09.413924Z"
    }
   },
   "source": [
    "embeddings = model.encode(question)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T01:30:27.267482Z",
     "start_time": "2024-05-13T01:30:16.504089Z"
    }
   },
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "\n",
    "reranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True)\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T01:31:35.220531Z",
     "start_time": "2024-05-13T01:31:35.197741Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T01:32:55.261188Z",
     "start_time": "2024-05-13T01:31:37.420607Z"
    }
   },
   "source": [
    "tokenizerId = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-id-en\")\n",
    "modelId = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-id-en\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source.spm:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52101da6cab34349921456b24a9b1907"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "target.spm:   0%|          | 0.00/796k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6954162027604b199c946278727b1d3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0cf0aa585994f1eb3d5dd49ee29416e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/291M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c00ea1656af043aa9482fcdee21ca763"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb2bbe3b64764951bc0b1d20e4423061"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T01:34:20.131072Z",
     "start_time": "2024-05-13T01:33:02.350096Z"
    }
   },
   "source": [
    "tokenizerEnId = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-id\")\n",
    "modelEnId = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-id\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "430cc14de9ac4d869f4e5e82a1ed2561"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b46d7b558ef54092aa667eb918058367"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source.spm:   0%|          | 0.00/796k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b7b1362daec46efa22f3976f88e2b9d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "target.spm:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ef278ae12d145d98b3bcf612832a459"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31bd2a9ce25b456789c4895e90cb22e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/291M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3fd73a9a76804001818d0376d20ca23f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45c2b7a8f21b40fd9e443841fde23581"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T01:40:18.837350Z",
     "start_time": "2024-05-13T01:39:13.406914Z"
    }
   },
   "source": [
    "tokenizerInc = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-inc-en\")\n",
    "modelInc = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-inc-en\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source.spm:   0%|          | 0.00/969k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eeb34f476985489d99e065666351164f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0662bc2628d40e69b8bc3ab473d8f62"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.93M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a3d5647a51a41c897bbd3342aea7075"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/306M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f2e216e14e44f7da57989f8eec812fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de0c8e86b5e84a7892d554dae46b49ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T01:49:36.707715Z",
     "start_time": "2024-05-13T01:41:13.255836Z"
    }
   },
   "source": [
    "tokenizerEnInc = AutoTokenizer.from_pretrained(\"thilina/mt5-sinhalese-english\")\n",
    "modelEnInc = AutoModelForSeq2SeqLM.from_pretrained(\"thilina/mt5-sinhalese-english\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57f9822d4f664744919c61d705acf65d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T02:18:22.945378Z",
     "start_time": "2024-05-13T02:18:15.637438Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizerVi = AutoTokenizer.from_pretrained(\"VietAI/envit5-translation\")\n",
    "modelVi = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/envit5-translation\")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T02:18:36.163750Z",
     "start_time": "2024-05-13T02:18:26.753753Z"
    }
   },
   "source": [
    "input_ids = tokenizerEnInc(\"How are you\", return_tensors=\"pt\").input_ids\n",
    "outputs = modelEnInc.generate(input_ids=input_ids)\n",
    "translatedSentence = tokenizerEnInc.batch_decode(outputs, skip_special_tokens=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T02:18:39.572071Z",
     "start_time": "2024-05-13T02:18:39.496517Z"
    }
   },
   "source": [
    "def translateToEng(sentence, originLanguage):\n",
    "    if (originLanguage == 'English'):\n",
    "        return sentence\n",
    "    elif (originLanguage == 'Vietnamese'):\n",
    "        input_ids = tokenizerVi(sentence, return_tensors=\"pt\",padding=True).input_ids\n",
    "        outputs = modelVi.generate(input_ids=input_ids, max_length=512)\n",
    "        translatedSentence = tokenizerVi.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return translatedSentence[0][4:]\n",
    "    elif (originLanguage == 'Indonesian'):\n",
    "        input_ids = tokenizerId(sentence, return_tensors=\"pt\",padding=True).input_ids\n",
    "        outputs = modelId.generate(input_ids=input_ids, max_length=512)\n",
    "        translatedSentence = tokenizerId.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return translatedSentence[0]\n",
    "    elif (originLanguage == 'Sinhala'):\n",
    "        input_ids = tokenizerInc(sentence, return_tensors=\"pt\",padding=True).input_ids\n",
    "        outputs = modelInc.generate(input_ids=input_ids, max_length=512)\n",
    "        translatedSentence = tokenizerInc.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return translatedSentence[0]"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T02:18:42.185912Z",
     "start_time": "2024-05-13T02:18:42.176334Z"
    }
   },
   "source": [
    "def translateFromEng(sentence, originLanguage):\n",
    "    if (originLanguage == 'English'):\n",
    "        return sentence\n",
    "    elif (originLanguage == 'Vietnamese'):\n",
    "        input_ids = tokenizerVi(sentence, return_tensors=\"pt\",padding=True).input_ids\n",
    "        outputs = modelVi.generate(input_ids=input_ids, max_length=512)\n",
    "        translatedSentence = tokenizerVi.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return translatedSentence[0][4:]\n",
    "    elif (originLanguage == 'Indonesian'):\n",
    "        input_ids = tokenizerEnId(sentence, return_tensors=\"pt\",padding=True).input_ids\n",
    "        outputs = modelEnId.generate(input_ids=input_ids, max_length=512)\n",
    "        translatedSentence = tokenizerEnId.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return translatedSentence[0]\n",
    "    elif (originLanguage == 'Sinhala'):\n",
    "        input_ids = tokenizerEnInc(sentence, return_tensors=\"pt\",padding=True).input_ids\n",
    "        outputs = modelEnInc.generate(input_ids=input_ids, max_length=512)\n",
    "        translatedSentence = tokenizerEnInc.batch_decode(outputs, skip_special_tokens=True)\n",
    "        return translatedSentence[0]"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T04:21:58.880001Z",
     "start_time": "2024-05-13T04:21:58.478848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import speech_recognition as sr\n",
    "import scipy.io.wavfile\n",
    "\n",
    "def speech_to_text(audio):\n",
    "    # audio is a tuple, need to extract the content part\n",
    "    rate, data = audio\n",
    "\n",
    "    # Write the audio data to a wav file\n",
    "    scipy.io.wavfile.write('temp.wav', rate, data)\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile('temp.wav') as source:\n",
    "        audio_data = r.record(source)\n",
    "        text = r.recognize_google(audio_data)\n",
    "        return text"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T03:50:49.688336Z",
     "start_time": "2024-05-13T03:50:42.885292Z"
    }
   },
   "source": [
    "def return_answer(user_question, recording, qLanguage, aLanguage):\n",
    "    # user_question = translateToEng(user_question, qLanguage)\n",
    "    if user_question:\n",
    "        print('text is provided')\n",
    "        user_question = user_question\n",
    "    else:\n",
    "        print('voice is provided')\n",
    "        # If no typed question, then take the voice input, convert it to text\n",
    "        user_question = speech_to_text(recording)\n",
    "\n",
    "    q_embedding = model.encode(user_question)\n",
    "\n",
    "    cos_sim = util.cos_sim(q_embedding, embeddings)\n",
    "\n",
    "    val = []\n",
    "\n",
    "    for i in range(len(cos_sim[0])):\n",
    "        val.append(cos_sim[0][i].item())\n",
    "\n",
    "    p_answer = answer.copy()\n",
    "    p_question = question.copy()\n",
    "\n",
    "    for i in range(len(val)):\n",
    "        for j in range(i + 1, len(val)):\n",
    "            if (val[i] < val[j]):\n",
    "                temp = val[i]\n",
    "                val[i] = val[j]\n",
    "                val[j] = temp\n",
    "\n",
    "                temp = p_answer[i]\n",
    "                p_answer[i] = p_answer[j]\n",
    "                p_answer[j] = temp\n",
    "                temp = p_question[i]\n",
    "                p_question[i] = p_question[j]\n",
    "                p_question[j] = temp\n",
    "\n",
    "    answer1 = \"Sorry we don't know the answer\"\n",
    "    answer2 = \"\"\n",
    "    answer3 = \"\"\n",
    "    if (reranker.compute_score([p_question[0], user_question]) >= -6):\n",
    "        answer1 = translateFromEng(p_answer[0], aLanguage)\n",
    "    if (reranker.compute_score([p_question[1], user_question]) >= -6):\n",
    "        answer2 = translateFromEng(p_answer[1], aLanguage)\n",
    "    if (reranker.compute_score([p_question[2], user_question]) >= -6):\n",
    "        answer3 = translateFromEng(p_answer[2], aLanguage)\n",
    "\n",
    "    return (answer1, answer2, answer3)\n",
    "\n",
    "translateFromEng(\"Hello\",\"Sinhala\");\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T04:22:05.085340Z",
     "start_time": "2024-05-13T04:22:04.863091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr # type: ignore\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=return_answer,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Typed Question\"),\n",
    "        gr.Audio(label=\"Voice Question\"),\n",
    "        gr.Dropdown(\n",
    "            [\"English\", \"Indonesian\", \"Vietnamese\", \"Sinhala\"], label=\"Question language\", value=\"English\"\n",
    "        ),\n",
    "        gr.Dropdown(\n",
    "            [\"English\", \"Indonesian\", \"Vietnamese\", \"Sinhala\"], label=\"Answer language\", value=\"English\"\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[gr.Textbox(label=\"Answer 1\"), gr.Textbox(label=\"Answer 2\"), gr.Textbox(label=\"Answer 3\")]\n",
    ")\n",
    "demo.launch()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
